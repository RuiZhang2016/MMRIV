{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import gc\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 285 ms, sys: 231 ms, total: 517 ms\n",
      "Wall time: 652 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = train[train.columns[1:]].values/255\n",
    "Y = train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n",
      "709\n"
     ]
    }
   ],
   "source": [
    "print(train.info())\n",
    "print(np.sum(np.max(train,axis=0)>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../datasets/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST/raw/train-images-idx3-ubyte.gz to ../datasets/MNIST/raw\n",
      "Using downloaded and verified file: ../datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ../datasets/MNIST/raw\n",
      "Using downloaded and verified file: ../datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ../datasets/MNIST/raw\n",
      "Using downloaded and verified file: ../datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../datasets/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../datasets/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST/raw/train-images-idx3-ubyte.gz to ../datasets/MNIST/raw\n",
      "Using downloaded and verified file: ../datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ../datasets/MNIST/raw\n",
      "Using downloaded and verified file: ../datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ../datasets/MNIST/raw\n",
      "Using downloaded and verified file: ../datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../datasets/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\"../datasets\", train=True, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor()])), batch_size=60000)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"../datasets\", train=False, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor()])), batch_size=10000)\n",
    "train_data, test_data = list(train_loader), list(test_loader)\n",
    "images_list = [train_data[0][0].numpy(), test_data[0][0].numpy()]\n",
    "labels_list = [train_data[0][1].numpy(), test_data[0][1].numpy()]\n",
    "\n",
    "images = np.concatenate(images_list, axis=0)\n",
    "labels = np.concatenate(labels_list, axis=0)\n",
    "idx = list(range(images.shape[0]))\n",
    "random.shuffle(idx)\n",
    "images = images[idx]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n"
     ]
    }
   ],
   "source": [
    "images2 = np.array([e.flatten() for e in images])\n",
    "plt.imshow(images[120,0]*255)\n",
    "print(labels[120])\n",
    "plt.show()\n",
    "\n",
    "ii = 0\n",
    "for i in range(images2.shape[1]):\n",
    "    if np.std(images2[:,i])>0.1:\n",
    "        ii+= 1\n",
    "print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof = np.zeros((X.shape[0], 10))\n",
    "test_preds = 0\n",
    "train_oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.9171428571428571\n",
      "Fitting fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.9185714285714286\n",
      "Fitting fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.9134523809523809\n",
      "Fitting fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.9151190476190476\n",
      "Fitting fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.919404761904762\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, random_state=137)\n",
    "\n",
    "for jj, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(\"Fitting fold\", jj+1)\n",
    "    train_features = X[train_index]\n",
    "    train_target = Y[train_index]\n",
    "    \n",
    "    val_features = X[val_index]\n",
    "    val_target = Y[val_index]\n",
    "    \n",
    "    model = LogisticRegression(C=20, solver='lbfgs', multi_class='multinomial')\n",
    "    model.fit(train_features, train_target)\n",
    "    val_pred = model.predict_proba(val_features)\n",
    "    train_oof[val_index] = val_pred\n",
    "    print(\"Fold accuracy:\", accuracy_score(val_target, np.argmax(val_pred, axis=1)))\n",
    "    test_preds += model.predict_proba(test)/n_splits\n",
    "    del train_features, train_target, val_features, val_target\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9167380952380952\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y, np.argmax(train_oof, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(test_preds, axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "submission['Label'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_preds', test_preds)\n",
    "np.save('train_oof', train_oof)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
